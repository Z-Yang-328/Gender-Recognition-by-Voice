{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
      "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
      "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
      "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
      "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
      "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
      "\n",
      "          kurt    sp.ent       sfm  ...    centroid   meanfun    minfun  \\\n",
      "0   274.402906  0.893369  0.491918  ...    0.059781  0.084279  0.015702   \n",
      "1   634.613855  0.892193  0.513724  ...    0.066009  0.107937  0.015826   \n",
      "2  1024.927705  0.846389  0.478905  ...    0.077316  0.098706  0.015656   \n",
      "3     4.177296  0.963322  0.727232  ...    0.151228  0.088965  0.017798   \n",
      "4     4.333713  0.971955  0.783568  ...    0.135120  0.106398  0.016931   \n",
      "\n",
      "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
      "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
      "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
      "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
      "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
      "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangzhibo5947/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random\n",
    "\n",
    "voice =pd.read_csv('voice.csv')\n",
    "voice = pd.DataFrame(voice)\n",
    "print(voice.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of df after 0th intertion of this loop is (6336, 21)\n",
      "shape of df after 1th intertion of this loop is (12672, 21)\n",
      "shape of df after 2th intertion of this loop is (25344, 21)\n",
      "shape of df after 3th intertion of this loop is (50688, 21)\n",
      "shape of df after 4th intertion of this loop is (101376, 21)\n",
      "shape of df after 5th intertion of this loop is (202752, 21)\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    copy = voice\n",
    "    copy['meanfreq']=copy['meanfreq']+random.gauss(.0001,.001) # add noice to mean freq var\n",
    "    voice=voice.append(copy,ignore_index=True) # make voice df 2x as big\n",
    "    print(\"shape of df after {0}th intertion of this loop is {1}\".format(i,voice.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label = voice.pop(\"label\")\n",
    "\n",
    "# converts from dataframe to np array\n",
    "voice=voice.values\n",
    "\n",
    "# convert train labels to one hots\n",
    "train_labels = pd.get_dummies(label)\n",
    "# make np array\n",
    "train_labels = train_labels.values\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(voice,train_labels,test_size=0.2)\n",
    "# # so no we have predictors and y values, separated into test and train\n",
    "\n",
    "x_train,x_test,y_train,y_test = np.array(x_train,dtype='float32'), np.array(x_test,dtype='float32'), np.array(y_train,dtype='float32'), np.array(y_test,dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train looks like:\n",
      " [[ 0.18717898  0.04334165  0.19327044  0.16509435  0.21396226  0.04886793\n",
      "   1.6974895   5.56550884  0.89263111  0.3544755   0.19327044  0.18975395\n",
      "   0.14567631  0.04692082  0.2742857   1.14283288  0.0234375   6.1640625\n",
      "   6.140625    0.12009586]] \n",
      "and y train looks like:\n",
      " [[ 1.  0.]]\n",
      "shape of x_train is: \n",
      " (162201, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train looks like:\\n\",x_train[1:2],\"\\nand y train looks like:\\n\",y_train[1:2])\n",
    "\n",
    "\n",
    "print(\"shape of x_train is: \\n\",x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# place holder for inputs. feed in later\n",
    "x = tf.placeholder(\"float\", [None, 20])\n",
    "\n",
    "# # take 20 features to 1000 nodes in hidden layer. why? just cuz?\n",
    "w1 = tf.Variable(tf.random_normal([20, 1000],stddev=.5,name='w1'))\n",
    "# # add biases for each node\n",
    "b1 = tf.Variable(tf.zeros([1000]))\n",
    "# calculate activations \n",
    "hidden_output = tf.nn.softmax(tf.matmul(x, w1) + b1)\n",
    "\n",
    "# bring from 10 nodes to 2 for my output\n",
    "w2 = tf.Variable(tf.random_normal([1000, 2],stddev=.5,name='w2'))\n",
    "\n",
    "b2 = tf.Variable(tf.zeros([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholder for correct values \n",
    "y_ = tf.placeholder(\"float\", [None,2])\n",
    "# #implement model. these are predicted ys\n",
    "y = tf.nn.softmax(tf.matmul(hidden_output, w2) + b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(y, y_, name='xentropy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_step = opt.minimize(loss, var_list=[w1,b1,w2,b2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "tf_accuracy = tf.reduce_mean(tf.cast(tf_correct_prediction, \"float\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mini_batch(x,y):\n",
    "    rows=np.random.choice(x.shape[0], 100)\n",
    "    return x[rows], y[rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start session\n",
    "sess = tf.Session()\n",
    "summary_writer = tf.train.SummaryWriter('voices')\n",
    "#summary_writer = tf.train.SummaryWriter('voices', sess.graph)\n",
    "\n",
    "# # init all vars\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 0 and cost is 69.904296875\n",
      "epoch is 100 and cost is 67.90319061279297\n",
      "epoch is 200 and cost is 66.94023132324219\n",
      "epoch is 300 and cost is 62.849586486816406\n",
      "epoch is 400 and cost is 62.152748107910156\n",
      "epoch is 500 and cost is 61.532554626464844\n",
      "epoch is 600 and cost is 59.95722961425781\n",
      "epoch is 700 and cost is 57.5360107421875\n",
      "epoch is 800 and cost is 56.6322021484375\n",
      "epoch is 900 and cost is 56.70622253417969\n",
      "epoch is 1000 and cost is 55.18450927734375\n",
      "epoch is 1100 and cost is 55.0582389831543\n",
      "epoch is 1200 and cost is 58.599830627441406\n",
      "epoch is 1300 and cost is 52.8678092956543\n",
      "epoch is 1400 and cost is 55.328834533691406\n",
      "epoch is 1500 and cost is 55.005558013916016\n",
      "epoch is 1600 and cost is 46.590702056884766\n",
      "epoch is 1700 and cost is 51.926727294921875\n",
      "epoch is 1800 and cost is 48.08849334716797\n",
      "epoch is 1900 and cost is 53.03516387939453\n",
      "epoch is 2000 and cost is 50.501712799072266\n",
      "epoch is 2100 and cost is 46.83556365966797\n",
      "epoch is 2200 and cost is 48.89889907836914\n",
      "epoch is 2300 and cost is 50.27192687988281\n",
      "epoch is 2400 and cost is 51.869449615478516\n",
      "epoch is 2500 and cost is 46.15122985839844\n",
      "epoch is 2600 and cost is 45.753318786621094\n",
      "epoch is 2700 and cost is 48.8521728515625\n",
      "epoch is 2800 and cost is 50.982181549072266\n",
      "epoch is 2900 and cost is 45.7472038269043\n",
      "epoch is 3000 and cost is 46.68254089355469\n",
      "epoch is 3100 and cost is 44.62654495239258\n",
      "epoch is 3200 and cost is 49.7057991027832\n",
      "epoch is 3300 and cost is 47.63068389892578\n",
      "epoch is 3400 and cost is 46.39063262939453\n",
      "epoch is 3500 and cost is 46.96360778808594\n",
      "epoch is 3600 and cost is 43.92713928222656\n",
      "epoch is 3700 and cost is 45.398590087890625\n",
      "epoch is 3800 and cost is 45.02263259887695\n",
      "epoch is 3900 and cost is 44.980445861816406\n",
      "epoch is 4000 and cost is 45.85183334350586\n",
      "epoch is 4100 and cost is 46.39734649658203\n",
      "epoch is 4200 and cost is 43.14059066772461\n",
      "epoch is 4300 and cost is 44.914772033691406\n",
      "epoch is 4400 and cost is 39.726314544677734\n",
      "epoch is 4500 and cost is 40.79608154296875\n",
      "epoch is 4600 and cost is 43.86204528808594\n",
      "epoch is 4700 and cost is 43.245635986328125\n",
      "epoch is 4800 and cost is 45.170562744140625\n",
      "epoch is 4900 and cost is 39.184486389160156\n",
      "epoch is 5000 and cost is 40.39702606201172\n",
      "epoch is 5100 and cost is 38.891544342041016\n",
      "epoch is 5200 and cost is 40.700096130371094\n",
      "epoch is 5300 and cost is 40.074222564697266\n",
      "epoch is 5400 and cost is 42.20857620239258\n",
      "epoch is 5500 and cost is 42.213260650634766\n",
      "epoch is 5600 and cost is 40.44049072265625\n",
      "epoch is 5700 and cost is 38.86134719848633\n",
      "epoch is 5800 and cost is 38.89815902709961\n",
      "epoch is 5900 and cost is 40.187103271484375\n",
      "epoch is 6000 and cost is 42.7425422668457\n",
      "epoch is 6100 and cost is 35.15252685546875\n",
      "epoch is 6200 and cost is 41.59291076660156\n",
      "epoch is 6300 and cost is 38.47576904296875\n",
      "epoch is 6400 and cost is 41.72919464111328\n",
      "epoch is 6500 and cost is 37.696868896484375\n",
      "epoch is 6600 and cost is 39.30023956298828\n",
      "epoch is 6700 and cost is 37.51710510253906\n",
      "epoch is 6800 and cost is 39.3774299621582\n",
      "epoch is 6900 and cost is 39.5319709777832\n",
      "epoch is 7000 and cost is 35.67705535888672\n",
      "epoch is 7100 and cost is 38.80371856689453\n",
      "epoch is 7200 and cost is 40.836517333984375\n",
      "epoch is 7300 and cost is 41.555538177490234\n",
      "epoch is 7400 and cost is 40.04511642456055\n",
      "epoch is 7500 and cost is 38.5709342956543\n",
      "epoch is 7600 and cost is 42.67733383178711\n",
      "epoch is 7700 and cost is 39.39702606201172\n",
      "epoch is 7800 and cost is 38.92677307128906\n",
      "epoch is 7900 and cost is 41.27179718017578\n",
      "epoch is 8000 and cost is 36.52080535888672\n",
      "epoch is 8100 and cost is 38.29669189453125\n",
      "epoch is 8200 and cost is 38.291534423828125\n",
      "epoch is 8300 and cost is 39.7724723815918\n",
      "epoch is 8400 and cost is 39.953487396240234\n",
      "epoch is 8500 and cost is 35.763427734375\n",
      "epoch is 8600 and cost is 39.230674743652344\n",
      "epoch is 8700 and cost is 38.46220397949219\n",
      "epoch is 8800 and cost is 38.7565803527832\n",
      "epoch is 8900 and cost is 38.94139099121094\n",
      "epoch is 9000 and cost is 36.866180419921875\n",
      "epoch is 9100 and cost is 39.904449462890625\n",
      "epoch is 9200 and cost is 39.145362854003906\n",
      "epoch is 9300 and cost is 39.112186431884766\n",
      "epoch is 9400 and cost is 39.03582763671875\n",
      "epoch is 9500 and cost is 39.92802429199219\n",
      "epoch is 9600 and cost is 36.2711296081543\n",
      "epoch is 9700 and cost is 34.83102798461914\n",
      "epoch is 9800 and cost is 35.05234909057617\n",
      "epoch is 9900 and cost is 38.24165344238281\n"
     ]
    }
   ],
   "source": [
    "ntrials = 10000\n",
    "for i in range(ntrials):\n",
    "    # get mini batch\n",
    "    a,b=get_mini_batch(x_train,y_train)\n",
    "    # run train step, feeding arrays of 100 rows each time\n",
    "    _, cost =sess.run([train_step,loss], feed_dict={x: a, y_: b})\n",
    "    if i%100 ==0:\n",
    "    \tprint(\"epoch is {0} and cost is {1}\".format(i,cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40551, 2)\n",
      "Test accuracy: 0.957263708114624\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "\n",
    "result = sess.run(tf_accuracy, feed_dict={x: x_test, \n",
    "                                          y_: y_test})\n",
    "\n",
    "print(\"Train accuracy: {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9562333226203918\n"
     ]
    }
   ],
   "source": [
    "result = sess.run(tf_accuracy, feed_dict={x:x_train,\n",
    "                                          y_ : y_train})\n",
    "print(\"Test accuracy: {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
