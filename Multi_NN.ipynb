{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import exp, array, random, dot\n",
    "\n",
    "\n",
    "class NeuronLayer():\n",
    "    def __init__(self, number_of_neurons, number_of_inputs_per_neuron):\n",
    "        self.synaptic_weights = 2 * random.random((number_of_inputs_per_neuron, number_of_neurons)) - 1\n",
    "\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, layer1, layer2):\n",
    "        self.layer1 = layer1\n",
    "        self.layer2 = layer2\n",
    "\n",
    "    # The Sigmoid function, which describes an S shaped curve.\n",
    "    # We pass the weighted sum of the inputs through this function to\n",
    "    # normalise them between 0 and 1.\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + exp(-x))\n",
    "\n",
    "    # The derivative of the Sigmoid function.\n",
    "    # This is the gradient of the Sigmoid curve.\n",
    "    # It indicates how confident we are about the existing weight.\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    # We train the neural network through a process of trial and error.\n",
    "    # Adjusting the synaptic weights each time.\n",
    "    def train(self, training_set_inputs, training_set_outputs, number_of_training_iterations):\n",
    "        for iteration in range(number_of_training_iterations):\n",
    "            # Pass the training set through our neural network\n",
    "            output_from_layer_1, output_from_layer_2 = self.think(training_set_inputs)\n",
    "\n",
    "            # Calculate the error for layer 2 (The difference between the desired output\n",
    "            # and the predicted output).\n",
    "            layer2_error = training_set_outputs - output_from_layer_2\n",
    "            layer2_delta = layer2_error * self.__sigmoid_derivative(output_from_layer_2)\n",
    "\n",
    "            # Calculate the error for layer 1 (By looking at the weights in layer 1,\n",
    "            # we can determine by how much layer 1 contributed to the error in layer 2).\n",
    "            layer1_error = layer2_delta.dot(self.layer2.synaptic_weights.T)\n",
    "            layer1_delta = layer1_error * self.__sigmoid_derivative(output_from_layer_1)\n",
    "\n",
    "            # Calculate how much to adjust the weights by\n",
    "            layer1_adjustment = training_set_inputs.T.dot(layer1_delta)\n",
    "            layer2_adjustment = output_from_layer_1.T.dot(layer2_delta)\n",
    "\n",
    "            # Adjust the weights.\n",
    "            self.layer1.synaptic_weights += layer1_adjustment\n",
    "            self.layer2.synaptic_weights += layer2_adjustment\n",
    "\n",
    "    # The neural network thinks.\n",
    "    def think(self, inputs):\n",
    "        output_from_layer1 = self.__sigmoid(dot(inputs, self.layer1.synaptic_weights))\n",
    "        output_from_layer2 = self.__sigmoid(dot(output_from_layer1, self.layer2.synaptic_weights))\n",
    "        return output_from_layer1, output_from_layer2\n",
    "\n",
    "    # The neural network prints its weights\n",
    "    def print_weights(self):\n",
    "        print (\"    Layer 1 (4 neurons, each with 3 inputs): \")\n",
    "        print (self.layer1.synaptic_weights)\n",
    "        print (\"    Layer 2 (1 neuron, with 4 inputs):\")\n",
    "        print (self.layer2.synaptic_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangzhibo5947/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2534\n",
      "634\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv('voice.csv')\n",
    "label = all_data.pop('label')\n",
    "\n",
    "all_data = all_data.values\n",
    "\n",
    "label.replace(['male','female'], [1, 0], inplace = True)\n",
    "label = label.values\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(all_data, label, test_size = 0.2)\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = np.array(train_data, dtype = 'float32'), np.array(test_data, dtype = 'float32'),np.array(train_labels, dtype = 'float32'),np.array(test_labels, dtype = 'float32')\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.38387426e-38]\n",
      " [  2.13199477e-38]\n",
      " [  2.97906989e-39]\n",
      " ..., \n",
      " [  6.24345215e-28]\n",
      " [  2.57543264e-38]\n",
      " [  2.81211080e-33]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #Seed the random number generator\n",
    "    random.seed(1)\n",
    "\n",
    "    # Create layer 1 (4 neurons, each with 3 inputs)\n",
    "    layer1 = NeuronLayer(10, 20)\n",
    "\n",
    "    # Create layer 2 (a single neuron with 4 inputs)\n",
    "    layer2 = NeuronLayer(1, 10)\n",
    "\n",
    "    # Combine the layers to create a neural network\n",
    "    neural_network = NeuralNetwork(layer1, layer2)\n",
    "\n",
    "    \n",
    "\n",
    "    # The training set. We have 7 examples, each consisting of 3 input values\n",
    "    # and 1 output value.\n",
    "    training_set_inputs = train_data\n",
    "    training_set_outputs = train_labels.reshape(2534,1)\n",
    "\n",
    "    # Train the neural network using the training set.\n",
    "    # Do it 60,000 times and make small adjustments each time.\n",
    "    neural_network.train(training_set_inputs, training_set_outputs, 10000)\n",
    "\n",
    "\n",
    "    # Test the neural network with a new situation.\n",
    "    \n",
    "    hidden_state, output = neural_network.think(train_data)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
